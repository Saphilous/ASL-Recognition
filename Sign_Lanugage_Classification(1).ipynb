{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H5nA8fQuYGgk"
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84O_3aOPszT1"
   },
   "source": [
    "Now, we have to load the zip file from our google drive and unzip it for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YCw8nbduUek",
    "outputId": "c2c6b56f-b977-4874-dabb-2e7c8c6eeba3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_ref = zipfile.ZipFile(r'C:\\Users\\jaswa\\Dropbox\\PC\\Desktop\\ASL Recognition\\archive(1).zip', mode = 'r')\n",
    "print(zip_ref.namelist())\n",
    "zip_ref.extractall(\"/tmp\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IvJwtSTwcCd"
   },
   "source": [
    "Now that we have the data, we can proceed to clean it up and prepare it for training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIfFFs_0xw3I"
   },
   "source": [
    "First, let us import all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HkwvQCLkxyTS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils, callbacks\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLcAykIkwkUR",
    "outputId": "74fcbb87-ba64-4e99-872f-2fe93aacb79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78300 images belonging to 29 classes.\n",
      "Found 8700 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rescale=1./255,\n",
    "                         rotation_range=10,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         brightness_range=[0.2, 1.0],\n",
    "                         zoom_range=0.2,\n",
    "                         fill_mode=\"nearest\",\n",
    "                         validation_split=0.1) \n",
    "train = gen.flow_from_directory(\"/tmp/asl_alphabet_train/asl_alphabet_train\", \n",
    "                                                            target_size=(64, 64), subset=\"training\",batch_size=256)\n",
    "val = gen.flow_from_directory(\"/tmp/asl_alphabet_train/asl_alphabet_train\", \n",
    "                                                            target_size=(64, 64), subset=\"validation\",batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzL3fBEhyGk6",
    "outputId": "c7abccfe-c06d-4e2f-8935-c721073aeba5"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(VGG16(weights=\"imagenet\",input_shape=(64,64,3),include_top=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(29,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YX4QjJKZyNuy"
   },
   "outputs": [],
   "source": [
    "opt = Adam(0.00001)\n",
    "loss = CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oWMYQheRyPJR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,loss=loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7ujvg65YyXPQ"
   },
   "outputs": [],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n",
    "                                        patience=5, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk2G9fFyycAB",
    "outputId": "8adec4f2-9fde-4144-84e8-b0e22ea22030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "306/306 [==============================] - 261s 751ms/step - loss: 1.9244 - accuracy: 0.4867 - val_loss: 0.9928 - val_accuracy: 0.7813\n",
      "Epoch 2/11\n",
      "306/306 [==============================] - 161s 525ms/step - loss: 0.4477 - accuracy: 0.8930 - val_loss: 0.4541 - val_accuracy: 0.8667\n",
      "Epoch 3/11\n",
      "306/306 [==============================] - 160s 520ms/step - loss: 0.2041 - accuracy: 0.9532 - val_loss: 0.3237 - val_accuracy: 0.8984\n",
      "Epoch 4/11\n",
      "306/306 [==============================] - 161s 526ms/step - loss: 0.1218 - accuracy: 0.9720 - val_loss: 0.2664 - val_accuracy: 0.9177\n",
      "Epoch 5/11\n",
      "306/306 [==============================] - 159s 520ms/step - loss: 0.0868 - accuracy: 0.9800 - val_loss: 0.2556 - val_accuracy: 0.9206\n",
      "Epoch 6/11\n",
      "306/306 [==============================] - 159s 519ms/step - loss: 0.0640 - accuracy: 0.9853 - val_loss: 0.2332 - val_accuracy: 0.9290\n",
      "Epoch 7/11\n",
      "306/306 [==============================] - 169s 551ms/step - loss: 0.0508 - accuracy: 0.9879 - val_loss: 0.2144 - val_accuracy: 0.9341\n",
      "Epoch 8/11\n",
      "306/306 [==============================] - 169s 551ms/step - loss: 0.0407 - accuracy: 0.9902 - val_loss: 0.2341 - val_accuracy: 0.9291\n",
      "Epoch 9/11\n",
      "306/306 [==============================] - 169s 552ms/step - loss: 0.0344 - accuracy: 0.9920 - val_loss: 0.2267 - val_accuracy: 0.9322\n",
      "Epoch 10/11\n",
      "306/306 [==============================] - 172s 562ms/step - loss: 0.0324 - accuracy: 0.9920 - val_loss: 0.2166 - val_accuracy: 0.9379\n",
      "Epoch 11/11\n",
      "306/306 [==============================] - 166s 543ms/step - loss: 0.0277 - accuracy: 0.9930 - val_loss: 0.2169 - val_accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,validation_data = val,epochs = 11,shuffle = True,verbose = 1, callbacks = [earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5kjeLPmBrh2"
   },
   "source": [
    "Now, let us try predicting some alphabets from images taken off the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6tuwj8TeBwwD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['asl_alphabet_test'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ImageDataGenerator(rescale=1./255).flow_from_directory(\"/tmp/asl_alphabet_test/\",\n",
    "                                    target_size=(64, 64), class_mode= 'categorical', shuffle = False)\n",
    "\n",
    "test.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "H7YFarOSm7wi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[293.4463806152344, 0.0357142873108387]\n",
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', 27: 'nothing', 28: 'space'}\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(test, verbose = 0)\n",
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred)\n",
    "\n",
    "print(res)\n",
    "\n",
    "#mapping the labels\n",
    "labels = (train.class_indices)\n",
    "lables = dict((v, k) for k, v in labels.items())\n",
    "print(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "t-KGJbTUmif_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test)\n",
    "\n",
    "for i in pred:\n",
    "  print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sign Lanugage Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
